{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMnrq1QgGDFIGH9V0efKU7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rk0803/Assignment3/blob/main/Assignment3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5vd0-NQDTr"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AX-Z1wokswB",
        "outputId": "ae8254e8-c99f-4aab-ce0c-32917cca3708"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdo5rEGZk12H",
        "outputId": "5660222b-86e7-416d-d9e6-157ca11a3b5b"
      },
      "source": [
        "def get_device():\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device('cuda')\n",
        "  else:\n",
        "    return torch.device('cpu')\n",
        "device=get_device()\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne0HS_DXl1ii"
      },
      "source": [
        "def to_device(data,device):\n",
        "  if isinstance(data,(list,tuple)):\n",
        "      return[to_device(x,device) for x in data]\n",
        "  return data.to(device,non_blocking=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EB64RSkQQQ7"
      },
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr5CTMNmQa5V"
      },
      "source": [
        "class MySet(Dataset):\n",
        "  def __init__(self,csv_file):\n",
        "    self.data=pd.read_csv(csv_file)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    r=self.data.iloc[index]\n",
        "    label=torch.tensor(r.is_up_day,dtype=torch.long)\n",
        "    sample=self.normalize(torch.tensor([r.open,r.high,r.low,r.close]))\n",
        "    return sample, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOcIkxu-Gugq"
      },
      "source": [
        "# Training set of MNIST data set is created."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_EITia7RZpp"
      },
      "source": [
        "train_set=torchvision.datasets.MNIST(\n",
        "    root='./data'\n",
        "    ,train=True\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([transforms.ToTensor()])\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws6QMH4USIsf"
      },
      "source": [
        "train_loader=torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt1Ttk4Ity6m"
      },
      "source": [
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L14h57lfnmRT",
        "outputId": "138f0923-4efa-41dc-c88f-9152f3445f00"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution \n",
        "        #kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        # 6 input channels to second layer and 12 output channels, \n",
        "        #5X5 convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        # flattening the output to further use in fully connected layers\n",
        "        self.fc1 = nn.Linear(192, 120) \n",
        "        self.fc2 = nn.Linear(120, 60)\n",
        "        self.fc3 = nn.Linear(60, 10) \n",
        "        self.fc4 = nn.Linear(20,100)\n",
        "        self.fc5 = nn.Linear(100,60)\n",
        "        self.out = nn.Linear(60,19)\n",
        "\n",
        "   def forward(self, x,y):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x,kernel_size=2,stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x,kernel_size=2,stride=2)\n",
        "        x = x.reshape(-1,12*4*4) # flattening the other dimensions of output \n",
        "        #except the batch side\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        imgdig=x #image digit output is captured here\n",
        "        x = torch.cat((x,y),dim=1) # Concatenation of one-hot vector of \n",
        "        #random digit which is the second input\n",
        "        x = torch.tanh(self.fc4(x))\n",
        "        x = torch.tanh(self.fc5(x))\n",
        "        x = self.out(x)\n",
        "        return x,imgdig\n",
        "\n",
        "\n",
        "net = Net() # creating an instance of the NN created above\n",
        "print(net) # to check out the parameters."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
            "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
            "  (fc4): Linear(in_features=20, out_features=100, bias=True)\n",
            "  (fc5): Linear(in_features=100, out_features=60, bias=True)\n",
            "  (out): Linear(in_features=60, out_features=19, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76kbZB6VJbM8"
      },
      "source": [
        "Get the number of correct labels outputted\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_02f-9Bb5W7"
      },
      "source": [
        "def get_num_correct(preds,labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfokKsbfJPTa"
      },
      "source": [
        "To create the set of 60000 random digits in batche of size 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRMXinIC1tAH"
      },
      "source": [
        "import random\n",
        "from random import randrange"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n5ZVheiBz_a"
      },
      "source": [
        "import numpy as np\n",
        "yr=np.array([[random.randrange(0,9,1) for j in range(100)] for i in range(600)])\n",
        "yr=torch.as_tensor(yr)\n",
        "yr=to_device(yr,device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijbb906Kb4yv",
        "outputId": "726ad35b-c2ea-4101-cdbd-432c09d623ee"
      },
      "source": [
        "#training Neural Net with all batches\n",
        "net=Net()\n",
        "to_device(net,device)\n",
        "trainloader=torch.utils.data.DataLoader(train_set,batch_size=100)\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum =0.9)\n",
        "for epoch in range(50):\n",
        "  total_loss=0\n",
        "  total_correct=0\n",
        "  i=0\n",
        "  for batch in train_loader:\n",
        "    batch=to_device(batch,device)\n",
        "    y=yr[i] # pickup the first batch of random digits \n",
        "    i+=1\n",
        "    y1=to_device(F.one_hot(y,10),device) # convert into one-hot vector notation\n",
        "    images,labels=batch  #first batch from training set of image data set.\n",
        "    sumlabint=y+labels   #output labels for the sum of two digits \n",
        "    preds,img1=net(images,y1)\n",
        "    loss1=F.cross_entropy(img1,labels)\n",
        "    loss2=F.cross_entropy(preds,sumlabint)\n",
        "    loss=loss1+loss2\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()  #Calculate gradients\n",
        "    optimizer.step() # Update weights\n",
        "    total_loss += loss.item()\n",
        "    total_correct+=(get_num_correct(img1,labels))\n",
        "  print(\"epoch \", epoch,\"total_correct: \", total_correct, \"loss \",total_loss)   \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  0 total_correct:  39283 loss  1998.9191895723343\n",
            "epoch  1 total_correct:  57964 loss  727.6856839060783\n",
            "epoch  2 total_correct:  58591 loss  322.17051205039024\n",
            "epoch  3 total_correct:  58898 loss  156.61982273310423\n",
            "epoch  4 total_correct:  59111 loss  99.50963361561298\n",
            "epoch  5 total_correct:  59256 loss  79.14698752947152\n",
            "epoch  6 total_correct:  59366 loss  65.65596918854862\n",
            "epoch  7 total_correct:  59475 loss  54.1232724301517\n",
            "epoch  8 total_correct:  59530 loss  45.398660878650844\n",
            "epoch  9 total_correct:  59598 loss  39.936515281908214\n",
            "epoch  10 total_correct:  59652 loss  33.82143662078306\n",
            "epoch  11 total_correct:  59654 loss  31.559487613849342\n",
            "epoch  12 total_correct:  59685 loss  28.070366208441556\n",
            "epoch  13 total_correct:  59725 loss  25.562164240982383\n",
            "epoch  14 total_correct:  59757 loss  21.562899586977437\n",
            "epoch  15 total_correct:  59782 loss  19.795338658615947\n",
            "epoch  16 total_correct:  59782 loss  20.211533706169575\n",
            "epoch  17 total_correct:  59850 loss  15.50324680074118\n",
            "epoch  18 total_correct:  59815 loss  17.072971617802978\n",
            "epoch  19 total_correct:  59869 loss  13.214073745300993\n",
            "epoch  20 total_correct:  59882 loss  11.739649218623526\n",
            "epoch  21 total_correct:  59922 loss  8.662868772633374\n",
            "epoch  22 total_correct:  59913 loss  9.394004853093065\n",
            "epoch  23 total_correct:  59933 loss  8.040497096488252\n",
            "epoch  24 total_correct:  59894 loss  10.100023203180172\n",
            "epoch  25 total_correct:  59931 loss  7.354420217568986\n",
            "epoch  26 total_correct:  59947 loss  6.122299691895023\n",
            "epoch  27 total_correct:  59930 loss  6.8235172723652795\n",
            "epoch  28 total_correct:  59917 loss  8.74695967102889\n",
            "epoch  29 total_correct:  59924 loss  7.559447387000546\n",
            "epoch  30 total_correct:  59848 loss  13.746785958181135\n",
            "epoch  31 total_correct:  59899 loss  9.36246134666726\n",
            "epoch  32 total_correct:  59893 loss  8.631601449742448\n",
            "epoch  33 total_correct:  59888 loss  9.829225064837374\n",
            "epoch  34 total_correct:  59882 loss  9.977604771091137\n",
            "epoch  35 total_correct:  59904 loss  8.781149281421676\n",
            "epoch  36 total_correct:  59926 loss  6.7441188740194775\n",
            "epoch  37 total_correct:  59948 loss  4.759055336820893\n",
            "epoch  38 total_correct:  59942 loss  4.995715998695232\n",
            "epoch  39 total_correct:  59943 loss  5.691054474096745\n",
            "epoch  40 total_correct:  59966 loss  3.232892676081974\n",
            "epoch  41 total_correct:  59966 loss  3.3284424680750817\n",
            "epoch  42 total_correct:  59935 loss  5.68214044731576\n",
            "epoch  43 total_correct:  59924 loss  6.352366442384664\n",
            "epoch  44 total_correct:  59931 loss  6.2410566552425735\n",
            "epoch  45 total_correct:  59965 loss  3.629620299267117\n",
            "epoch  46 total_correct:  59968 loss  3.143560955824796\n",
            "epoch  47 total_correct:  59970 loss  3.059338564402424\n",
            "epoch  48 total_correct:  59980 loss  1.7257304365630262\n",
            "epoch  49 total_correct:  59981 loss  1.4969356569636147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7h9J3PHuU1M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c10xvpecMwTw"
      },
      "source": [
        "test_set=torchvision.datasets.MNIST(\n",
        "    root='./data'\n",
        "    ,train=False\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([transforms.ToTensor()])\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqjP2D-KuVUA"
      },
      "source": [
        "yr=np.array([[random.randrange(0,9,1) for j in range(100)] for i in range(100)])\n",
        "yr=torch.as_tensor(yr)\n",
        "yr=to_device(yr,device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwfxyoXuuVUA",
        "outputId": "73390f92-75e8-4967-c3c9-0410b0339fdf"
      },
      "source": [
        "testloader=torch.utils.data.DataLoader(test_set,batch_size=100)\n",
        "total_correct_dig=0\n",
        "total_correct_sum=0\n",
        "i=0\n",
        "for batch in testloader:\n",
        "    batch=to_device(batch,device)\n",
        "    images,labels=batch\n",
        "    y=yr[i] # pick up the batch of random digits\n",
        "    i+=1\n",
        "    y1=to_device(F.one_hot(y,10),device) # convert it into one-vector\n",
        "    sumlabint=y+labels   # Create the output labels for sum of image digit and random digit\n",
        "    preds,img1=net(images,y1)\n",
        "    total_correct_dig+=(get_num_correct(img1,labels))\n",
        "    total_correct_sum+=(get_num_correct(preds,sumlabint))\n",
        "print(\"total_correct_digits: \", total_correct_dig, \"total_correct_sum: \", total_correct_sum) \n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_correct_digits:  9915 total_correct_sum:  9917\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}